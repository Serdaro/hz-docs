= Production Checklist
:description: The production checklist provides a set of best practices and recommendations to ensure a smooth transition to a production environment which runs a Hazelcast cluster.
[[production-checklist]]

{description} You should plan for and consider the following areas.


== Data Size Calculation Recommendations

Total data size should be calculated based on the combination of primary data and backup data. For example, if you have configured your cluster with a backup count of 2, then total memory consumed is actually 3x larger than the primary data size (primary + backup + backup). Partition sizes of 50MB or less are recommended.

== Partition Size/Count Calculation Recommendations

The number of internal partitions a Hazelcast member uses can be xref:ROOT:capacity-planning.adoc#partition-count[configured], but must be uniform across all members in the cluster.
An optimal partition count and size establish a balance between the
number of partitions on each member and the data amount on each partition.
You can consider the following when deciding on a partition count.

* The partition count should be a prime number. This helps to minimize the collision of keys across
partitions, ensuring more consistent lookup times.
* A partition count which is too low constrains the cluster. The count should
be large enough for a balanced data or task distribution so that each member
does not manage too few partitions.
* A partition size of 50MB or less typically ensures good performance. Larger clusters may be able to use up to 100MB partition sizes, but will likely also require larger JVM heap sizes to accomodate the increase in data flow.

If you are a Hazelcast Enterprise customer using the High-Density Data Store with large data sizes,
we recommend a large increase in partition count, starting with 5009 or higher.

The partition count cannot be easily changed after a cluster is created, so if you have a large cluster be sure to test and set an optimum partition count prior to deployment. If you need to change the partition count after a cluster is already running, you will need to schedule a maintenance window to entirely bring the cluster down. If your cluster uses the xref:storage:persistence.adoc[Persistence] or xref:cp-subsystem:persistence.adoc[CP Persistence] features, those persistent files will need to be removed after the cluster is shut down, as they contain references to the previous partition count. Once all member configurations are updated, and any persistent data structure files are removed, the cluster can be safely restarted.
